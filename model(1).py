# -*- coding: utf-8 -*-
"""Model

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zZae8nCo6txuBxasIq_rlvtdxzTMD-_j

# 1: Update rules

# Connect-while-in-range

The connect_while_in_range update rule has 3 steps: movement, information diffusion, and link updating.

To move, each agent chooses from a uniformly random distribution of its adjacent integer coordinates, including its current location. In other words, it selects a tile at random in its Moore neighborhood. To avoid agents sharing the same position, however, tiles currently occupied by other agents are excluded- as are positions out of bounds (below 0 or above g). If all tiles are occupied, the agent remains in place. (Note: this means that as N approaches gxg, the coordinate space becomes 'saturated,' reaching a state where each agent remains in place, each at a unique coordinate).

To diffuse, the model includes 4 possibilities: 1) SI diffusion, 2) complex contagion, 3) cultural evolution 4) potion task. In SI diffusion, agents have the state "susceptible" (trait=0) or "infected" (trait=1). _N init_ initial agents are 'infected' at t=0, and at every timestep, each infected agent _i_ can diffuse to their network connections _j_ with probability _P(connect)_ ("pc" in the code). In complex contagion ([Centola 2007](https://https://www.jstor.org/stable/10.1086/521848)), diffusion to agent _i_ in state S depends on the number of connected agents _j_ that are in state I. More specifically, the probability for _i_ to adopt state I in this simulation is (j(I)/N)w : the number of network neighbors in state I, j(I), divided by population size _N_, multiplied by a weight value _w_.

The cultural evolution model is a simplification based on population genetics models that track the intergenerational transmission of two genetic variants 'A' and 'B'. Rather than one infectious state with a transmission probability, and a susceptible state, agents can be now be in two states that each have their own transmission probability, pA and pB. When these probabilities are the same, this is called unbiased transmission, and when they are different it's biased transmission.

More specifically, in this model, each agent randomly selects one of their network neighbors each timestep. When that neighbor's state is different from the agent's state (say agent i has A and j has B), it is adopted with its associated probability (in this case i has a pB probability of adopting B).  

The potion task, based on an experiment ([Derex and Boyd 2016](https://www.pnas.org/doi/full/10.1073/pnas.1518798113)) and existing models implementing that experiment ([lMoser and Smaldino 2022](https://osf.io/preprints/socarxiv/n3hc6), [Migliano et al. 2020](https://www.science.org/doi/10.1126/sciadv.aax5913)), is more specific. It simulates the progression of agents through a problem space with two 'trajectories' A and B through the combination of 'ingredients' to make a virtual 'potion.' There are a number of valid combinations of ingredients which produce a higher-level potion, which is associated with a higher score. The final, highest-score product requires the highest-level items from both trajectories. The original experiment found that more sparsely connected groups are succesful at exploring both trajectories and therefore finding the final item, while fully connected groups usually only optimized within on trajectory.

In the potion task simulation, agents are initialized with a starting inventory. Then, they select a random network neighbor, and the two agents randomly select 3 items from their inventory. Higher-scored items are more likely to be selected. Then, if this is a valid combination, both agents add the combination product item to their inventory. If a new valid combination was found, each of the two agents involved diffuse this new item to their network neighbors with probability _pdiff_.

Finally in the connect-while-in range update rule, agents update links. To do so, they check for each agent whether they are within a Euclidean distance of range _r_. They connect with those agents who are. If there were agents that were connected and have now moved out of range, they disconnect.

The function assumes as input the graph G (a networkx network object), initialized as empty graph at t=0, or as updated state (output of this function) afterwards. It also takes a value for grid size g such that the coordinate space is g x g, communication range r implemented as Euclidian distance.

The remaining optional paramters set the diffusion processes. The default diffusion process is SI, for which parameter P needs to be set between 0 and 1. For complex contagion, set compl to true and set the social weight value between 0 and 1. For cultural evolution, set CE to True and set pA and pB between 0 and 1. For potion task, set potion to True and pdiff betweeon 0 and 1.

Agents are updated in a random order each timestep.

# Connect at random: non-spatial null model

In the non-spatial model, instead of moving in a coordinate space, each timestep agents connect to each other agent with probability P (connect) which is set globally as the same for all agents. In other words, the networks are generated by an Erdos-Renyi [source] process for generating random graphs.

For link updating, in order to make the random graph network formation process dynamic and comparable to the range model, there is an additional parameter P(disconnect) which is set to the inverse of P(connect). This mimicks the connection probabilities of the agents in the range model. For randomly moving ranged agents, the probability of connecting to another agent is proportional to the percentage of the total area covered by the communication range. If range covers the whole coordinate space (i.e., for a circular Euclidean range and a square coordinate space, if (2Ï€r^2) : (g x g) >= 1, each agent always connect and networks are fully connected, mirroring the P(connect)=1 setting. If range does not cover the whole coordinate space, the area not covered by an agent's range is equal to the inverse of the area covered, mirroring the disconnect probability P(disconnect) = 1 - P(connect).

For some thoughts on "comparable" settings between the range and the null model, see "2. Run_simulation", where this function is actually called.

The function takes as input the G_null networkx object graph, 'pc' for P(connect), and the same diffusion parameters as the range model.

# 2: Running the simulation

After the update rules, the below script contains the function that runs R rounds of T-timestep simulations. The user can specify (1) which parameter (range _r_, population size_N_, or grid size_g_) is the varying parameter while the other parameters remain constant and (2) which diffusion process (SI, complex contagion, cultural evolution, or potion task; see above) is simulated.

# Subfunctions
The following are some functions for operations repeated multiple times in the below run_simulation function.

"Collect_stats" takes the networks created within a timestep by the above agent behavior functions, and calculates the properties of the networks and diffusion process at that timestep. The network properties calculated: number of connected components, size of largest component, population average degree, gini index of degree distribution, population average clustering coefficient, average shortest path length, and small-world-index. The network stucture measures are summed each timestep because the output will be time-averages, taking the cumulative measure and dividing by T.

[Explanation of measures: link to "test setup" section of paper]

The SI diffusion and complex contagion process properties calculated: population I("infected")-state frequency, and t_fixation, which stores the time at which I-frequency = 1 (fixation of the trait) was reached. The potion task properties calculated: like fixation time, "crossover" records the timestep at which the potion task process is complete. Unlike the diffusion process, the task is considered "complete" not when 100% of the population is 'infected', but when the problem space is completely explored. This is when one of the most complex items, A4 or B4, is discovered, which requires combining the most complex items from both trajectories of the problem space. This is considered a "crossover event."

The function takes as input parameters the parameter values Q, i, G, and N that will have been declared within the run_simulation function (see below), plus the variables for the statistics this function collects, which will be initialized earlier in the run_simulation function.

"Initialize_graph" creates N agents and a coordinatespace of g by g. Then, it initializes a networkx empty graph, adds to this graph a "population" of networkx nodes, assigns unique positions to each agent, and 'infects' an initial amount N_init of agents. In run_simulation below, null graphs are initialized much the same way, except without a position in a coordinate space. When the diffusion process is set to potion task, agents are also initialized with a starting inventory.

The function takes as input parameters N,g,N_init, and Q, which are set by calling run_simulation, and i, which is the current iteration index (when initialize_graph is called) of the for-loop over the varying input parameter.

"get_trait_data": The structure of the output parameters measuring the diffusion process is different from that of the output parameters measuring network measures. The difference is that in the diffusion process outputs, the frequency over time is preserved, rather than averaged over the whole round. Therefore, the trait data needs to be collected seperately, in order for it be called in the right loop.

# Run simulation function

Finally, here is the run_simulation function. It's a series of nested for-loops: the first loop 'layer' is over the number of rounds R, the second over the varying input parameter, and the third over the number of timesteps T. All of these are set when calling the run_simulation function; see also "4. Calling the functions."

The varying input paramater is set by the variable 'Q', which is an index value of the list of possible varying parameters [r,N,g]. So if Q=0, varying parameter is r; if Q=1, N; etc. The varying parameter will be the "stop" argument in a for-loop which will loop over integer values until reaching the inputted value.

Before looping, the function initializes the 'multirun' dictionaries, which will be the outputs of this function. In the R-loop, the 'singlerun' dictionaries are initialized, which store the outputs of one iteration of r. In the varying parameter loop, the networks are initialized, and the output variables are initialized that will represent the time-averaged network measures of one iteration over 100 timesteps. Finally, in the T-loop, the range and null model update rules are executed, and the network measures at t collected. Then, outside of the T-loop again, these collected measures are averaged over time (except for connectedness, which is not an average but a simple count) and put into the singlerun dictionaries as an entry {i:measure value}, where i is the current value of the varying input parameter. Finally, outside of the varying parameter loop but still inside the R-loop, the multirun dictionaries are updated with an entry {R:singlerun entry}. The final multirun dictionaries that are returned by this function, then, will have R entries of the form {R:{i:{network measure average value}}; except for the trait frequency dictionary, which preserves frequency over time, and has the structure {R:{i{t:trait frequency}}}.

As to which settings the null model takes: if Q=0 so r is the varying parameter, the analagous parameter is p(connect). This will simply go through 10 steps between 0 and 1 (the complete meaningful range of p(connect)). Otherwise, it's set so that p(connect) = r:g. For example, if r=2 and g=10, pc = 0.2. This match isn't completely exact, but gives comparable behavior. If Q=2 and so the varying parameter is g, no null model data is collected, because there is no null analogue to g. At Q=1 and Q=3, the parameters can simply be the same; the null model also contains N and P.

To run the simulation, call the run_simulation function. As a reminder, the arguments of run_simulation are: (R,r,N,g,T,P,N_init,Q). Choose an input parameter (r,N,g,P) to be varied. Input the corresponding value for Q: varying_parameter = list(range([r,N,g][Q])). Then, for the varying parameter, put the maximum value. For all other values, put a constant value. Below are some example settings.
"""

import networkx as nx
import numpy as np
import random
import matplotlib.pyplot as plt
import math
import scipy
import copy

#1: UPDATE RULES

def connect_ranged(G,orderlist,Range):
  for i in orderlist:
    for j in orderlist:
      if j > i:
        #if within range, create link; if an existing edge is now out of range, remove it.
        ij_distance = math.sqrt((G.nodes[j]["position"][0] - G.nodes[i]["position"][0]) ** 2 +
                                      (G.nodes[j]["position"][1] - G.nodes[i]["position"][1]) ** 2)
        if ij_distance <= Range:
          G.add_edge(i, j)
        elif G.has_edge(i, j):
          G.remove_edge(i, j)
  return G

def connect_random(G_null,orderlist,pc):
  pd = 1-pc
  for i in orderlist:
    for j in orderlist:
      if j > i:
        if (not G_null.has_edge(i,j)) and (random.random() < pc):
          #connect if random value between 0 and 1 is lower than the connection chance.
          #At 1 it is always lower, at 0 it never is.
          G_null.add_edge(i, j)
        if G_null.has_edge(i, j) and random.random() < pd:
          G_null.remove_edge(i, j)

  return G_null

  #cultural evolution model:

def biased_transmission(G,orderlist,pa,pb):
  for i in orderlist:
    neighbors_list = list(G.neighbors(i)) # Convert the iterator to a list
    if len(neighbors_list) > 0:
      j = random.choice(neighbors_list)
      if G.nodes[i]["trait"] == 'A' and G.nodes[j]['trait'] == 'B':
        if random.random() < pb:
          G.nodes[i]["trait"] = 'B'

      if G.nodes[i]["trait"] == 'B' and G.nodes[j]['trait'] == 'A':
        if random.random() < pa:
          G.nodes[i]["trait"] = 'A'

  return G

  #potion task: problem space, subfunctions and main function:

combination_list = [
    ['a1','a3','b2'],
    ['A1','b1','b2'],
    ['A2','a1','b1'],
    ['A3','B3','B1'],
    ['a1','b1','b3'],
    ['B1','a2','a3'],
    ['B2','a2','b1'],
    ['B3','A3','B2']
]

sorted_combination_list = []

for entry in combination_list:
  sorted_combination_list.append(sorted(entry))

discovery_list = [
    ['A1','a',48,48],
    ['A2','a',109,109],
    ['A3','a',188,188],
    ['A4','a',358,358],
    ['B1','b',48,48],
    ['B2','b',109,109],
    ['B3','b',188,188],
    ['B4','b',358,358]
]


starting_inventory = [
    ["a1", 'a', 6, 0], #Potion, trajectory, value, score
    ["a2", 'a', 8, 0],
    ["a3", 'a', 10, 0],
    ["b1", 'b', 6, 0],
    ["b2", 'b', 8, 0],
    ["b3", 'b', 10, 0]]

    #two agents select a total of three items from their inventories:

def select_item(i, j, G):
    #first decide whether 1 or 2 items are picked
    one_or_two = random.randint(1, 2)

    #each agent assigns odds of item use based on current inventory scores:
    values_i = [item[2] for item in G.nodes[i]["inventory"]]
    values_j = [item[2] for item in G.nodes[j]["inventory"]]
    odds_i = [value / sum(values_i) for value in values_i]
    odds_j = [value / sum(values_j) for value in values_j]

    #Annoyingly,np.random.choice requires a 1-dimensional (non-nested) list (and random.choice doesn't
    #have a replacement parameter, and random.sample() doesn't have weights), so i can't just
    #select "selection_i" directly as one of the items in the inventory. Instead, i first make the
    #1d list of item IDs only:
    itemnames_i = [item[0] for item in G.nodes[i]["inventory"]]
    itemnames_j = [item[0] for item in G.nodes[j]["inventory"]]

    #then select from the item names:
    selectedvalue_i = np.random.choice(itemnames_i, size=one_or_two, replace=False, p=odds_i)
    selectedvalue_j = np.random.choice(itemnames_j, size=3 - one_or_two, replace=False, p=odds_j)

    #then set selected items to the full items with these itemnames:
    selection_i = [item for item in G.nodes[i]["inventory"] if item[0] in selectedvalue_i]
    selection_j = [item for item in G.nodes[j]["inventory"] if item[0] in selectedvalue_j]

    if one_or_two == 1:
      item1 = selection_i[0]
      item2 = selection_j[0]
      item3 = selection_j[1]
    elif one_or_two == 2:
      item1 = selection_i[0]
      item2 = selection_i[1]
      item3 = selection_j[0]

    return item1, item2, item3

    #the three items are checked against the predefined list of valid combinations
    #into a higher-level item:

def combine_items(combination,i,j,G):
  discovery = []
  discovered = False
  #check if valid combination
  item_ids = sorted([i[0] for i in combination])
  #sort both so order of items doesn't matter
  for entry in combination_list:
    if item_ids == sorted(entry):
      index = sorted_combination_list.index(item_ids)
      discovery = discovery_list[index]
      if discovery not in G.nodes[i]["inventory"] and discovery not in G.nodes[j]["inventory"]:
        discovered = True
      else:
        discovered = False
  return discovery, discovered

  #if a higher-level item was discovered, transmit it to connected neighbors:

def diffuse_potion(agent,discovery,pdiff,G):
  neighborlist = list(G.neighbors(agent))
  for neighbor in neighborlist:
    #check if discovered item in neighbor inventory
    if discovery not in G.nodes[neighbor]["inventory"]:
      #that neighbor adds the item with probability p: innovation diffusion probability.
      if random.random() > pdiff:
        G.nodes[neighbor]["inventory"].append(discovery)

def potion_task(G,pdiff,orderlist):
  #If you like you can define the lists and parameters given globally in "initialization"
  #here instead.
  for i in orderlist:
    #select partner:
    neighbors_list = list(G.neighbors(i))
    #If there are neighbors (list is non-empty), do the interaction:
    if neighbors_list:
      j = random.choice(neighbors_list)
      combination = select_item(i,j,G)
      discovery, discovered = combine_items(combination,i,j,G)
      if discovered:
        #Update inventories to include the discovered item (again as [Id,Trajectory,Value,Score])
        G.nodes[i]["inventory"].append(discovery)
        G.nodes[j]["inventory"].append(discovery)
        if pdiff > 0:
          diffuse_potion(i,discovery,pdiff,G)
          diffuse_potion(j,discovery,pdiff,G)
    scores = [item[3] for item in G.nodes[i]["inventory"]]
    #set score to highest valued current item
    G.nodes[i]["score"] = max(scores)
  return G

  #SI diffusion and complex contagion:

def diffuse(G,orderlist,compl,weight,P):
  #Complex contagion: transmission probability is a weighted sum of the number of neighbors with trait = 1.
  if compl:
    for i in orderlist:
      count = 0
      for j in G.neighbors(i):
          if G.nodes[j]['state'] == 1:
              count += 1

      if G.nodes[i]['state'] == 0:
          # Complex contagion: Probability of adoption depends on the count of adopting neighbors
          adoption_prob = P + ((count/len(G.nodes)) * weight)
          if random.random() < adoption_prob:
              G.nodes[i]['state'] = 1
  else:

    #SI diffusion:
    for i in orderlist:
      for j in G.neighbors(i):
        if G.nodes[i]["state"] == 1 and G.nodes[j]['state'] == 0:
          if random.random() < P:
            G.nodes[j]["state"] = 1
          if G.nodes[j]["state"] == 1 and G.nodes[i]['state'] == 0:
            if random.random() < P:
              G.nodes[i]["state"] = 1

  return G

def move(G,orderlist,g):
  for i in orderlist:
    #list of positions currently occupied by other agents:
    occupied = list(G.nodes[j]["position"] for j in G.nodes)
    #retreive own current position:
    x, y = G.nodes[i]["position"]
    #Create list of positions in the Moore neighborhood:
    #(there's a smarter way of doing this with list comprehension, but that statement is about as long as just putting in the coordinates)
    neighborhood = [(x-1,y+1),(x,y+1),(x+1,y+1),(x-1,y),(x,y),(x+1,y),(x-1,y-1),(x,y-1),(x+1,y-1)]
    #Grid boundaries: if any of the available neighborhood positions would be below 0 or above g, delete them from the options:
    filtered_neighborhood = [(nx, ny) for nx, ny in neighborhood if 0 <= nx < g and 0 <= ny < g]
    #only move if position available (so if the list 'available' is non-empty), otherwise stay at current position:
    available = [pos for pos in filtered_neighborhood if pos not in occupied]
    if available:
      G.nodes[i]['position'] = random.choice(available)
  return G

def connect_when_in_range(G, g, Range, P, compl = False, weight=0, CE = False, pa = 0, pb = 0, potion = False, pdiff = 0):
  orderlist = random.sample(G.nodes,len(G.nodes))
  #random update order each timestep: take a random sample without replacement of the set of nodes of G,
  #of size N. In other words, arrange the nodes in a random order, which will be used to iterate over this timestep.

  #Random movement:
  G = move(G,orderlist,g)

  #Potion task:
  if potion:
    G = potion_task(G,pdiff,orderlist)

  elif CE:
    G = biased_transmission(G,orderlist,pa,pb)

  #Simple or complex contagion:
  else:
    G = diffuse(G,orderlist,compl,weight,P)

  #Range-based link updating:
  G = connect_ranged(G,orderlist,Range)

  return G

def connect_at_random(G_null,pc,P,compl=False,weight=0,CE=False,pa=0,pb=0,potion=False,pdiff=0):
  orderlist = random.sample(G_null.nodes,len(G_null.nodes))

  #Potion task:
  if potion:
    G_null = potion_task(G_null,pdiff,orderlist)

  elif CE:
    G_null = biased_transmission(G_null,orderlist,pa,pb)

  #Simple or complex contagion:
  else:
    G_null = diffuse(G_null,orderlist,compl,weight,P)

  G_null = connect_random(G_null,orderlist,pc)

  return G_null


#2: COLLECT STATS

#The collect_stats function will calculate, in the main run_simulation function, the network structure and diffusion statistics
#each timestep. These subfunctions calculate individual statistics.

#This function is adapted (for degree) from Moser & Smaldino's code for "Innovation-Facilitating Networks Create Inequality", from their github https://github.com/cmoserj/Potions-Model/blob/v1.0.0/README.md.
def compute_gini(G,N):
    degrees = list(G.degree)
    x = sorted([i[1] for i in degrees])
    if N*sum(x) !=0:
        B = sum( xi * (N-i) for i,xi in enumerate(x) ) / (N*sum(x))
        return (1 + (1/N) - 2*B)
    else:
      return "NA"

def calculate_smallworld_index(G):
  CG = nx.average_clustering(G)
  componentsG = list(nx.connected_components(G))
  avg_lengths_G = []
  for component in componentsG:
    subgraphG = G.subgraph(component)
    avg_lengths_G.append(nx.average_shortest_path_length(subgraphG))
  LG = sum(avg_lengths_G) / len(avg_lengths_G)
  m = len(G.edges)
  n = len(G.nodes)

  randomgraph = nx.gnm_random_graph(n,m)
  CR = nx.average_clustering(randomgraph)
  componentsR = list(nx.connected_components(randomgraph))
  avg_lengths_R = []
  for component in componentsR:
    subgraphR = randomgraph.subgraph(component)
    avg_lengths_R.append(nx.average_shortest_path_length(subgraphR))
  LR = sum(avg_lengths_R) / len(avg_lengths_R)

  if CR == 0:
    S = "NA"
  elif LR == 0:
    S = "NA"
  elif (LG/LR) == 0:
    S = "NA"
  else:
    S = (CG/CR)/(LG/LR)

  return(S,CG,LG)

def get_state_attributes(G,t,n,freq_t,fixation_list):
  #retrieve trait attributes, and calculate frequency, which = proportion of agents with trait = 1:
  states = nx.get_node_attributes(G,"state")
  count = sum(1 for node, state in states.items() if state == 1)
  freq = count/n
  freq_t.update({t:freq})
  if freq == 1:
    fixation_list.append(t)

  return freq_t, fixation_list

def get_CE_stats(G,t,n,freqAB_t,fixationAB_dict):
  traits = nx.get_node_attributes(G,"trait")
  countA = sum(1 for node, trait in traits.items() if trait == 'A')/n
  countB = sum(-1 for node, trait in traits.items() if trait == 'B')/n
  freqAB = countA + countB
  freqAB_t.update({t:freqAB})
  if freqAB == 1:
    t_fixationAB = t
    fixationAB_dict.update({t:'A'})
  if freqAB == -1:
    t_fixationAB = t
    fixationAB_dict.update({t:'B'})

  return freqAB_t, fixationAB_dict

def get_crossover(G,t,crossover,crossover_reached):
  for agent in G.nodes():
    items = [item[0] for item in G.nodes[agent]["inventory"]]
  if 'B4' in items or 'A4' in items:
    if crossover_reached == False:
      crossover = t+1
      crossover_reached = True
  return crossover,crossover_reached

def get_CE_stats(G,t,freqAB_t,fixationAB_dict):
  traits = nx.get_node_attributes(G,"trait")
  countA = sum(1 for node, trait in traits.items() if trait == 'A')/n
  countB = sum(-1 for node, trait in traits.items() if trait == 'B')/n
  freqAB = countA + countB
  freqAB_t.update({t:freqAB})
  if freqAB == 1:
    t_fixationAB = t
    fixationAB_dict.update({t:'A'})
  if freqAB == -1:
    t_fixationAB = t
    fixationAB_dict.append({t:'B'})

  return freqAB_t, fixationAB_dict

def collect_stats(Q,i,G,N,t,crossover,crossover_reached,freq_t,fixation_list,freqAB_t,fixationAB_dict,degree,clustering,aspl,nr_components,largest_component,distribution,SWness,CE,potion):
  if Q == 1:
    n = i
  else:
    n = N

  if potion:
    crossover,crossover_reached = get_crossover(G,t,crossover,crossover_reached)

  elif CE:
    freqAB_t, fixationAB_dict = get_CE_stats(G,t,n,freqAB_t,fixationAB_dict)

  else:
    freq_t, fixation_list = get_state_attributes(G,t,n,freq_t,fixation_list)

  #Collect network properties:

  components = list(nx.connected_components(G))
  #Size of the largest component:
  largest_component += len(max(components,key=len))
  #Number of connected components:
  nr_components += len(components)

  #Average degree:
  list_of_node_degrees = []
  for k in G.nodes:
    list_of_node_degrees.append(G.degree[k])
  degree += sum(list_of_node_degrees)/n

  #Degree distribution inequality:
  gini = compute_gini(G,N)
  distribution.append(gini)

  S, CG, LG = calculate_smallworld_index(G)
  SWness.append(S)

  #Clustering:
  clustering += CG

  #Average shortest path length:
  aspl += LG

  return crossover, crossover_reached, freq_t, fixation_list, freqAB_t, fixationAB_dict, degree, clustering, aspl, nr_components, largest_component, distribution, SWness

#In addition to collecting the output statistics, in run_simulation the networks/agent populations
# need to be initialized at each simulation round start:

def initialize_graph(N,g,N_init,Q,i,null,CE=False,potion=False):
    if Q == 1:
      n = i
    else:
      n = N

    G = nx.Graph()

    if null == False:
      #In the ranged graph, choose N unique positions as starting positions:
      coordinatespace = [(x,y) for x in range(g) for y in range(g)]
      initpos = random.sample(coordinatespace,n)
      for j in range(n):
        G.add_node(j, position = initpos[j])
    else:
      #In the null model, just create n agents:
      for j in range(n):
        G.add_node(j)

    if CE:
      #In the biased transmission model, initialize agents with A or B:
      for agent in range(n):
        G.nodes[agent]["trait"] = random.choice(['A','B'])
      #In the potion model, initialize agents with starting inventory:
    elif potion:
      for agent in range(n):
        G.nodes[agent]["inventory"] = copy.deepcopy(starting_inventory)
      #In the diffusion models, initialize N_init initially infected and N-N_init susceptible agents:
    else:
      for j in G.nodes:
        if j < N_init:
          G.nodes[j]["state"]=1
        else:
          G.nodes[j]["state"]=0
    return G

#Seperataly from the rest of the stats, diffusion process data is collected. It's seperate
#because time-structure is preserved in this data (the output is trait frequency over time),
#while network measure outputs are averaged over time each round.

def get_trait_data(round_number, fixation_list, freq_t, singlerun_fixation,singlerun_freq,CE):
  #only get the first time at which fixation is reached, and only get it if fixation was reached:
  if len(fixation_list) > 0:
    if CE:
      singlerun_fixation.update({round_number:list(fixation_list.keys())[0]})
    else:
       singlerun_fixation.update({round_number:fixation_list[0]})
  else:
    singlerun_fixation.update({round_number:"fixation not reached"})
  singlerun_freq.update({round_number:freq_t})

  return singlerun_fixation, singlerun_freq

#3: RUN SIMULATION

#Small-world-index and gini-index can be undefined (this happens sometimes at lower range settings because some properties
#will be 0 and these indices would require division by 0). Therefore, the following counts the number of undefined ("NA")
#and number of defined entries in distribution and SW lists, and updates the dictionary accordingly: "NA" if all entries undefined,
#weighted average (such that weights still sum to T) if 0 < entries < T, and simple time-average when no entries undefined.

def handle_undefined(singlerundict,round_number,resultslist,T):
  NA_count = len([item for item in resultslist if isinstance(item, str)])
  filtered_list = [item for item in resultslist if isinstance(item, float)]
  if NA_count == 0:
    singlerundict.update({round_number: sum(resultslist) / T})
  if NA_count == T:
    singlerundict.update({round_number: "NA"})
  if 0 < NA_count < T:
    weightvalue = T/(T-NA_count)
    weightedlist = [item*weightvalue for item in filtered_list]
    singlerundict.update({round_number: sum(weightedlist)/T})
  return(singlerundict)

def run_simulation(R, r, N, g, T, Q, P=0, N_init=0, compl=False, weight=0, CE=False, pa=0, pb=0, potion=False, pdiff=0):
    # Initialize the output dictionaries: will have the form {varying parameter:{"singlerun" dict}} (see below for "singlerun" dicts).
    multirun_freq = {}
    multirun_fixation = {}
    multirun_freqAB = {}
    multirun_fixationAB = {}

    multirun_degree = {}
    multirun_clustering = {}
    multirun_aspl = {}
    multirun_nr_components = {}
    multirun_largest_component = {}
    multirun_distribution = {}
    multirun_SWness = {}

    null_multirun_freq = {}
    null_multirun_fixation = {}
    null_multirun_freqAB = {}
    null_multirun_fixationAB = {}

    null_multirun_degree = {}
    null_multirun_clustering = {}
    null_multirun_aspl = {}
    null_multirun_nr_components = {}
    null_multirun_largest_component = {}
    null_multirun_distribution = {}
    null_multirun_SWness = {}

    multirun_crossover = {}
    null_multirun_crossover = {}

    # Q is a parameter that determines which input parameter is the varying parameter for the current simulation run.
    # It's an index value of the list of possible varying parameters [r, N, g].
    varying_parameter = [r, N, g][Q]

    for i in range(varying_parameter):
        # Skip the N=0 iteration, which just means empty graphs:
        if Q == 1 and i == 0:
            continue

        # Initialize the output dictionaries of a single simulation run: will have the form {round number:time-average network measure}.
        singlerun_degree = {}
        singlerun_clustering = {}
        singlerun_aspl = {}
        singlerun_nr_components = {}
        singlerun_largest_component = {}
        singlerun_distribution = {}
        singlerun_SWness = {}

        singlerun_freq = {}
        singlerun_fixation = {}
        singlerun_fixationAB = {}
        singlerun_freqAB = {}

        null_singlerun_degree = {}
        null_singlerun_clustering = {}
        null_singlerun_aspl = {}
        null_singlerun_nr_components = {}
        null_singlerun_largest_component = {}
        null_singlerun_distribution = {}
        null_singlerun_SWness = {}

        null_singlerun_freq = {}
        null_singlerun_fixation = {}
        null_singlerun_fixationAB = {}
        null_singlerun_freqAB = {}

        singlerun_crossover = {}
        null_singlerun_crossover = {}

        for round_number in range(R):
            # Initialize the variables storing the output parameter values at single timesteps:
            degree = 0
            clustering = 0
            aspl = 0
            nr_components = 0
            largest_component = 0
            distribution = []
            SWness = []

            crossover = 0

            freq = 0
            count = 0
            freq_t = {}

            freqAB = 0
            countAB = 0
            freqAB_t = {}

            t_fixation = 0
            fixation_list = []

            t_fixationAB = 0
            fixationAB_dict = {}

            null_degree = 0
            null_clustering = 0
            null_aspl = 0
            null_nr_components = 0
            null_largest_component = 0
            null_distribution = []
            null_SWness = []

            null_crossover = 0

            null_freq = 0
            null_count = 0
            null_freq_t = {}

            null_freqAB = 0
            null_countAB = 0
            null_freqAB_t = {}

            null_t_fixation = 0
            null_fixation_list = []

            null_t_fixationAB = 0
            null_fixationAB_dict = {}

            crossover_reached = False
            null_crossover_reached = False

            # t=0: initialize G as graph of N nodes with position and trait attributes; N_init nodes starting with trait = 1.
            G = initialize_graph(N, g, N_init, Q, i, False, CE, potion)
            G_null = initialize_graph(N, g, N_init, Q, i, True, CE, potion)

            for t in range(T):
                # Depending on the chosen Q-value, one of the model parameters is varied from 0 up to that value.
                # A null model is run alongside it, at matching settings.
                if Q == 0:
                    G = connect_when_in_range(G, g, i, P, compl, weight, CE, pa, pb, potion, pdiff)
                    if i <= 10:  # note this solution assumes i will always be integer values.
                        pc = list(np.round(np.linspace(0, 1, 11), 1))[i]
                        G_null = connect_at_random(G_null, pc, P, compl, weight, CE, pa, pb, potion, pdiff)
                elif Q == 1:
                    # In the varying N runs, N varies based on the above initialization of G and G_null.
                    G = connect_when_in_range(G, g, r, P, compl, weight, CE, pa, pb, potion, pdiff)
                    G_null = connect_at_random(G_null, r / g, P, compl, weight, CE, pa, pb, potion, pdiff)
                elif Q == 2:
                    G = connect_when_in_range(G, i, r, P, compl, weight, CE, pa, pb, potion, pdiff)
                    # no comparable null model here

                crossover, crossover_reached, freq_t, fixation_list, freqAB_t, fixationAB_dict, degree, clustering, aspl, nr_components, largest_component, distribution, SWness = collect_stats(Q, i, G, N, t, crossover,crossover_reached,
                                                                                                                                                                                                            freq_t, fixation_list, freqAB_t, fixationAB_dict, degree, clustering, aspl, nr_components, largest_component, distribution, SWness, CE, potion)

                if Q != 2:
                    # don't collect null stats if g is varying; no corresponding null model.
                    null_crossover, null_crossover_reached, null_freq_t, null_fixation_list, null_freqAB_t, null_fixationAB_dict, null_degree, null_clustering, null_aspl, null_nr_components, null_largest_component, null_distribution, null_SWness = collect_stats(Q, i, G_null, N, t,
                                                                                                                                                                                                                                                                                           null_crossover, null_crossover_reached, null_freq_t, null_fixation_list, null_freqAB_t, null_fixationAB_dict, null_degree, null_clustering, null_aspl, null_nr_components, null_largest_component, null_distribution, null_SWness, CE, potion)

            # In collect_stats, single-timestep values have been summed throughout a full round of 100 timesteps, and to get a time-average they are here divided by T.
            singlerun_degree.update({round_number: degree / T})
            singlerun_clustering.update({round_number: clustering / T})
            singlerun_aspl.update({round_number: aspl / T})
            singlerun_nr_components.update({round_number: nr_components / T})
            singlerun_largest_component.update({round_number: largest_component / T})
            singlerun_distribution = handle_undefined(singlerun_distribution,round_number,distribution,T)
            singlerun_SWness = handle_undefined(singlerun_SWness,round_number,SWness,T)

            # Potion task output: if crossover occurred, the "crossover" variable was set to True and cross_time keeps the timestep at which it did.
            if crossover_reached:
                singlerun_crossover.update({round_number: crossover})
            else:
                singlerun_crossover.update({round_number: "crossover not reached"})

            if CE:
                singlerun_fixationAB, singlerun_freqAB = get_trait_data(round_number, fixationAB_dict, freqAB_t, singlerun_fixationAB, singlerun_freqAB,CE)

            else:
                singlerun_fixation, singlerun_freq = get_trait_data(round_number, fixation_list, freq_t, singlerun_fixation, singlerun_freq,CE)

            if Q != 2:
                # Again, don't collect null data when input parameter is g.

              null_singlerun_degree.update({round_number: null_degree / T})
              null_singlerun_clustering.update({round_number: null_clustering / T})
              null_singlerun_aspl.update({round_number: null_aspl / T})
              null_singlerun_nr_components.update({round_number: null_nr_components / T})
              null_singlerun_largest_component.update({round_number: null_largest_component / T})
              null_singlerun_distribution = handle_undefined(null_singlerun_distribution,round_number,null_distribution,T)
              null_singlerun_SWness = handle_undefined(null_singlerun_SWness,round_number,null_SWness,T)

              if null_crossover_reached:
                  null_singlerun_crossover.update({round_number: null_crossover})
              else:
                  null_singlerun_crossover.update({round_number: "crossover not reached"})

              if CE:
                  null_singlerun_fixationAB, null_singlerun_freqAB = get_trait_data(round_number, null_fixationAB_dict, null_freqAB_t, null_singlerun_fixationAB, null_singlerun_freqAB,CE)

              else:
                  null_singlerun_fixation, null_singlerun_freq = get_trait_data(round_number, null_fixation_list, null_freq_t, null_singlerun_fixation, null_singlerun_freq,CE)

        multirun_degree.update({i: singlerun_degree})
        multirun_clustering.update({i: singlerun_clustering})
        multirun_aspl.update({i: singlerun_aspl})
        multirun_nr_components.update({i: singlerun_nr_components})
        multirun_largest_component.update({i: singlerun_largest_component})
        multirun_distribution.update({i: singlerun_distribution})
        multirun_SWness.update({i: singlerun_SWness})

        if potion:
            multirun_crossover.update({i: singlerun_crossover})

        elif CE:
            multirun_freqAB.update({i: singlerun_freqAB})
            multirun_fixationAB.update({i: singlerun_fixationAB})

        else:
            multirun_fixation.update({i: singlerun_fixation})
            multirun_freq.update({i: singlerun_freq})

        if Q != 2:
          if Q == 0:
            if i <= 10:
              param = list(np.round(np.linspace(0, 1, 11), 1))[i]
          else:
              param = i
          null_multirun_degree.update({param: null_singlerun_degree})
          null_multirun_clustering.update({param: null_singlerun_clustering})
          null_multirun_aspl.update({param: null_singlerun_aspl})
          null_multirun_nr_components.update({param: null_singlerun_nr_components})
          null_multirun_largest_component.update({param: null_singlerun_largest_component})
          null_multirun_distribution.update({param: null_singlerun_distribution})
          null_multirun_SWness.update({param: null_singlerun_SWness})

          if potion:
              null_multirun_crossover.update({param: null_singlerun_crossover})

          elif CE:
              null_multirun_freqAB.update({param: null_singlerun_freqAB})
              null_multirun_fixationAB.update({param: null_singlerun_fixationAB})

          else:
              null_multirun_fixation.update({param: null_singlerun_fixation})
              null_multirun_freq.update({param: null_singlerun_freq})

    return (multirun_crossover, multirun_freq, multirun_fixation, multirun_freqAB, multirun_fixationAB, multirun_degree, multirun_clustering, multirun_aspl, multirun_nr_components, multirun_largest_component, multirun_distribution, multirun_SWness, null_multirun_crossover,
            null_multirun_freq, null_multirun_fixation, null_multirun_freqAB, null_multirun_fixationAB, null_multirun_degree, null_multirun_clustering, null_multirun_aspl, null_multirun_nr_components, null_multirun_largest_component, null_multirun_distribution, null_multirun_SWness)
    # Note: if g is varying, null dictionaries will simply return empty.


#Calling the function for varying range between 0 and 10, R=100, T=100, N=10, g=10, SI diffusion P=0.05:

datar = run_simulation(100,11,10,10,100,0,P=0.05,N_init=1)

#Calling the function for varying N between 0 and 100, r=2, potion task:

#dataN = run_simulation(100,2,101,10,100,1,potion=True,pdiff=0.05)

#Calling the function for varying g between 0 and 50, N=10, r=5, complex contagion:

#datag = run_simulation(100,5,10,51,100,2,compl=True,weight=0.1)