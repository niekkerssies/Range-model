# -*- coding: utf-8 -*-
"""1. Connect-while-in-range run update rules and simulation

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zZae8nCo6txuBxasIq_rlvtdxzTMD-_j

# 1: Update rules

# Connect-while-in-range

The connect_while_in_range update rule has 3 steps: movement, information diffusion, and link updating.

To move, each agent chooses from a uniformly random distribution of its adjacent integer coordinates, including its current location. In other words, it selects a tile at random in its Moore neighborhood. To avoid agents sharing the same position, however, tiles currently occupied by other agents are excluded- as are positions out of bounds (below 0 or above g). If all tiles are occupied, the agent remains in place. (Note: this means that as N approaches gxg, the coordinate space becomes 'saturated,' reaching a state where each agent remains in place, each at a unique coordinate).

To diffuse, the current version of the model includes 3 possibilities: 1) SI diffusion, 2) complex contagion, 3) potion task. In SI diffusion, agents have the state "susceptible" (trait=0) or "infected" (trait=1). _N init_ initial agents are 'infected' at t=0, and at every timestep, each infected agent _i_ can diffuse to their network connections _j_ with probability _P(connect)_ ("pc" in the code). In complex contagion (Centola (...)), diffusion to agent _i_ in state S depends on the number of connected agents _j_ that are in state I. More specifically, the probability for _i_ to adopt state I in this simulation is (j(I)/N)w : the number of network neighbors in state I, j(I), divided by population size _N_, multiplied by a weight value _w_.

The potion task, based on (Derex and Boyd 2016) and existing models (Moser and Smaldino 2022, Migliano et al. 2020, (...)), is more specific. It simulates the progression of agents through a problem space with two 'trajectories' A and B through the combination of 'ingredients' to make a virtual 'potion.' There are a number of valid combinations of ingredients which produce a higher-level potion, which is associated with a higher score. The final, highest-score product requires the highest-level items from both trajectories. The original experiment found that more sparsely connected groups are succesful at exploring both trajectories and therefore finding the final item, while fully connected groups usually only optimized within on trajectory.

In the potion task simulation, agents are initialized with a starting inventory. Then, they select a random network neighbor, and the two agents randomly select 3 items from their inventory. Higher-scored items are more likely to be selected. Then, if this is a valid combination, both agents add the combination product item to their inventory. If a new valid combination was found, each of the two agents involved diffuse this new item to their network neighbors with probability _pdiff_.

Finally in the connect-while-in range update rule, agents update links. To do so, they check for each agent whether they are within a Euclidean distance of range _r_. They connect with those agents who are. If there were agents that were connected and have now moved out of range, they disconnect.

The function assumes as input the graph G (a networkx network object), initialized as empty graph at t=0, or as updated state (output of this function) afterwards. It also takes a value for grid size g such that the coordinate space is g x g, communication range r implemented as Euclidian distance, and the diffusion probability P.

Agents are updated in a random order each timestep.

# Connect at random: non-spatial null model

In the non-spatial model, instead of moving in a coordinate space, each timestep agents connect to each other agent with probability P (connect) which is set globally as the same for all agents. In other words, the networks are generated by an Erdos-Renyi [source] process for generating random graphs.

For link updating, in order to make the random graph network formation process dynamic and comparable to the range model, there is an additional parameter P(disconnect) which is set to the inverse of P(connect). This mimicks the connection probabilities of the agents in the range model. For randomly moving ranged agents, the probability of connecting to another agent is proportional to the percentage of the total area covered by the communication range. If range covers the whole coordinate space (i.e., for a circular Euclidean range and a square coordinate space, if (2Ï€r^2) : (g x g) >= 1, each agent always connect and networks are fully connected, mirroring the P(connect)=1 setting. If range does not cover the whole coordinate space, the area not covered by an agent's range is equal to the inverse of the area covered, mirroring the disconnect probability P(disconnect) = 1 - P(connect).

For some thoughts on "comparable" settings between the range and the null model, see "2. Run_simulation", where this function is actually called.

The function takes as input the G_null networkx object graph, 'pc' for P(connect), and P for the diffusion probability.

# 2: Running the simulation

After the update rules, the below script contains the function that runs R rounds of T-timestep simulations. The user can specify (1) which parameter (range _r_, population size_N_, or grid size_g_) is the varying parameter while the other parameters remain constant and (2) which diffusion process (SI, complex contagion, or potion task; see "1. Connect-while-in-range update rules") is simulated.

# Subfunctions
The following are some functions for operations repeated multiple times in the below run_simulation function.

"Collect_stats" takes the networks created within a timestep by the above agent behavior functions, and calculates the properties of the networks and diffusion process at that timestep. The network properties calculated: number of connected components, size of largest component, population average degree, gini index of degree distribution, population average clustering coefficient, number of timesteps at which a single connected component formed, and average shortest path length. The SI diffusion and complex contagion process properties calculated: population I-state frequency, and t_fixation, which stores the time at which frequency=1 (fixation of the trait) was reached. The potion task properties calculated: like fixation time, "crossover" records the timestep at which the potion task process is complete. Unlike the diffusion process, the task is considered "complete" not when 100% of the population is 'infected', but when the problem space is completely explored. This is when one of the most complex items, A4 or B4, is discovered, which requires combining the most complex items from both trajectories of the problem space (see "1. Connect-while-in-range update rules"). This is considered a "crossover event."
All measures except 'connectedness' are summed each timestep because the output will be time-averages, taking the cumulative measure and dividing by T.

The function takes as input parameters the parameter values Q, i, G, and N that will have been declared within the run_simulation function (see below), plus the variables for the statistics this function collects, which will be initialized earlier in the run_simulation function.

"Initialize_graph" creates N agents and a coordinatespace of g by g. Then, it initializes a networkx empty graph, adds to this graph a "population" of networkx nodes, assigns unique positions to each agent, and 'infects' an initial amount N_init of agents. In run_simulation below, null graphs are initialized much the same way, except without a position in a coordinate space. When the diffusion process is set to potion task, agents are also initialized with a starting inventory.

The function takes as input parameters N,g,N_init, and Q, which are set by calling run_simulation, and i, which is the current iteration index (when initialize_graph is called) of the for-loop over the varying input parameter; see run_simulation.

"get_trait_data": The structure of the output parameters measuring the diffusion process is different from that of the output parameters measuring network measures. The difference is that in the diffusion process outputs, the frequency over time is preserved, rather than averaged over the whole round. Therefore, the trait data needs to be collected seperately, in order for it be called in the right loop; see run_simulation.

# Run simulation function

Finally, here is the run_simulation function. It's a series of nested for-loops: the first loop 'layer' is over the number of rounds R, the second over the varying input parameter, and the third over the number of timesteps T. All of these are set when calling the run_simulation function; see also "4. Calling the functions."

The varying input paramater is set by the variable 'Q', which is an index value of the list of possible varying parameters [r,N,g]. So if Q=0, varying parameter is r; if Q=1, N; etc. The varying parameter will be the "stop" argument in a for-loop which will loop over integer values until reaching the inputted value.

Before looping, the function initializes the 'multirun' dictionaries, which will be the outputs of this function. In the R-loop, the 'singlerun' dictionaries are initialized, which store the outputs of one iteration of r. In the varying parameter loop, the networks are initialized, and the output variables are initialized that will represent the time-averaged network measures of one iteration over 100 timesteps. Finally, in the T-loop, the range and null model update rules are executed, and the network measures at t collected. Then, outside of the T-loop again, these collected measures are averaged over time (except for connectedness, which is not an average but a simple count) and put into the singlerun dictionaries as an entry {i:measure value}, where i is the current value of the varying input parameter. Finally, outside of the varying parameter loop but still inside the R-loop, the multirun dictionaries are updated with an entry {R:singlerun entry}. The final multirun dictionaries that are returned by this function, then, will have R entries of the form {R:{i:{network measure average value}}; except for the trait frequency dictionary, which preserves frequency over time, and has the structure {R:{i{t:trait frequency}}}.

As to which settings the null model takes: if Q=0 so r is the varying parameter, the analagous parameter is p(connect). This will simply go through 10 steps between 0 and 1 (the complete meaningful range of p(connect)). Otherwise, it's set so that p(connect) = r:g. For example, if r=2 and g=10, pc = 0.2. This match isn't completely exact, but gives comparable behavior. If Q=2 and so the varying parameter is g, no null model data is collected, because there is no null analogue to g. At Q=1 and Q=3, the parameters can simply be the same; the null model also contains N and P.

To run the simulation, call the run_simulation function. As a reminder, the arguments of run_simulation are: (R,r,N,g,T,P,N_init,Q). Choose an input parameter (r,N,g,P) to be varied. Input the corresponding value for Q: varying_parameter = list(range([r,N,g][Q])). Then, for the varying parameter, put the maximum value. For all other values, put a constant value. Below are some example settings.
"""

import networkx as nx
import numpy as np
import random
import matplotlib.pyplot as plt
import math
import scipy
import seaborn
import pandas
import copy

combination_list = [
    ['a1','a3','b2'],
    ['A1','b1','b2'],
    ['A2','a1','b1'],
    ['A3','B3','B1'],
    ['a1','b1','b3'],
    ['B1','a2','a3'],
    ['B2','a2','b1'],
    ['B3','A3','B2']
]

sorted_combination_list = []

for entry in combination_list:
  sorted_combination_list.append(sorted(entry))

discovery_list = [
    ['A1','a',48,48],
    ['A2','a',109,109],
    ['A3','a',188,188],
    ['A4','a',358,358],
    ['B1','b',48,48],
    ['B2','b',109,109],
    ['B3','b',188,188],
    ['B4','b',358,358]
]


starting_inventory = [
    ["a1", 'a', 6, 0], #Potion, trajectory, value, score
    ["a2", 'a', 8, 0],
    ["a3", 'a', 10, 0],
    ["b1", 'b', 6, 0],
    ["b2", 'b', 8, 0],
    ["b3", 'b', 10, 0]]

def combine_items(combination,i,j,G):
  discovery = []
  discovered = False
  #check if valid combination
  item_ids = sorted([i[0] for i in combination])
  #sort both so order of items doesn't matter
  for entry in combination_list:
    if item_ids == sorted(entry):
      index = sorted_combination_list.index(item_ids)
      discovery = discovery_list[index]
      if discovery not in G.nodes[i]["inventory"] and discovery not in G.nodes[j]["inventory"]:
        discovered = True
      else:
        discovered = False
  return discovery, discovered

def diffuse(agent,discovery,pdiff,G):
  neighborlist = list(G.neighbors(agent))
  for neighbor in neighborlist:
    #check if discovered item in neighbor inventory
    if discovery not in G.nodes[neighbor]["inventory"]:
      #that neighbor adds the item with probability p: innovation diffusion probability.
      if random.random() > pdiff:
        G.nodes[neighbor]["inventory"].append(discovery)

def potion_task(G,pdiff,orderlist):
  #If you like you can define the lists and parameters given globally in "initialization"
  #here instead.
  for i in orderlist:
    #select partner:
    neighbors_list = list(G.neighbors(i))
    #If there are neighbors (list is non-empty), do the interaction:
    if neighbors_list:
      j = random.choice(neighbors_list)
      combination = select_item(i,j,G)
      discovery, discovered = combine_items(combination,i,j,G)
      if discovered:
        #Update inventories to include the discovered item (again as [Id,Trajectory,Value,Score])
        G.nodes[i]["inventory"].append(discovery)
        G.nodes[j]["inventory"].append(discovery)
        if pdiff > 0:
          diffuse(i,discovery,pdiff,G)
          diffuse(j,discovery,pdiff,G)
    scores = [item[3] for item in G.nodes[i]["inventory"]]
    #set score to highest valued current item
    G.nodes[i]["score"] = max(scores)
  return G


def connect_while_in_range(G, g, Range, P, compl = False, weight=0, potion = False, pdiff = 0):
  orderlist = random.sample(G.nodes,len(G.nodes))
  #random update order each timestep: take a random sample without replacement of the set of nodes of G,
  #of size N. In other words, arrange the nodes in a random order, which will be used to iterate over this timestep.

  #Movement:
  for i in orderlist:
    #list of positions currently occupied by other agents:
    occupied = list(G.nodes[j]["position"] for j in G.nodes)
    #retreive own current position:
    x, y = G.nodes[i]["position"]
    #Create list of positions in the Moore neighborhood:
    #(there's a smarter way of doing this with list comprehension, but that statement is about as long as just putting in the coordinates)
    neighborhood = [(x-1,y+1),(x,y+1),(x+1,y+1),(x-1,y),(x,y),(x+1,y),(x-1,y-1),(x,y-1),(x+1,y-1)]
    #Grid boundaries: if any of the available neighborhood positions would be below 0 or above g, delete them from the options:
    filtered_neighborhood = [(nx, ny) for nx, ny in neighborhood if 0 <= nx < g and 0 <= ny < g]
    #only move if position available (so if the list 'available' is non-empty), otherwise stay at current position:
    available = [pos for pos in filtered_neighborhood if pos not in occupied]
    if available:
      G.nodes[i]['position'] = random.choice(available)

  #Potion task:
  if potion:
    G = potion_task(G,pdiff,orderlist)

  else:

    #Complex contagion: transmission probability is a weighted sum of the number of neighbors with trait = 1.
    if compl:
      for i in orderlist:
        count = 0
        for j in G.neighbors(i):
            if G.nodes[j]['trait'] == 1:
                count += 1

        if G.nodes[i]['trait'] == 0:
            # Complex contagion: Probability of adoption depends on the count of adopting neighbors
            adoption_prob = P + ((count/len(G.nodes)) * weight)
            if random.random() < adoption_prob:
                G.nodes[i]['trait'] = 1
    else:

      #SI diffusion:
      for i in orderlist:
        for j in G.neighbors(i):
          if G.nodes[i]["trait"] == 1 and G.nodes[j]['trait'] == 0:
            if random.random() < P:
              G.nodes[j]["trait"] = 1
            if G.nodes[j]["trait"] == 1 and G.nodes[i]['trait'] == 0:
              if random.random() < P:
                G.nodes[i]["trait"] = 1

  #Link updating:
  for i in orderlist:
    for j in orderlist:
      if j > i:
        #if within range, create link; if an existing edge is now out of range, remove it.
        ij_distance = math.sqrt((G.nodes[j]["position"][0] - G.nodes[i]["position"][0]) ** 2 +
                                      (G.nodes[j]["position"][1] - G.nodes[i]["position"][1]) ** 2)
        if ij_distance <= Range:
          G.add_edge(i, j)
        elif G.has_edge(i, j):
          G.remove_edge(i, j)

  return G

def connect_at_random(G_null,pc,P,compl=False,weight=0,potion=False,pdiff=0):
  pdis = 1-pc
  orderlist = random.sample(G_null.nodes,len(G_null.nodes))

  if potion:
    G_null = potion_task(G_null,pdis,orderlist)

  else:

    #Complex contagion: transmission probability is a weighted sum of the number of neighbors with trait = 1.
    if compl:
      for i in orderlist:
        count = 0
        for j in G_null.neighbors(i):
            if G_null.nodes[j]['trait'] == 1:
                count += 1

        if G_null.nodes[i]['trait'] == 0:
            # Complex contagion: Probability of adoption depends on the count of adopting neighbors
            adoption_prob = P + ((count/len(G_null.nodes)) * weight)
            if random.random() < adoption_prob:
                G_null.nodes[i]['trait'] = 1
    else:

      #Diffusion
      for i in orderlist:
        for j in G_null.neighbors(i):
          if G_null.nodes[i]["trait"] == 1 and G_null.nodes[j]['trait'] == 0:
            if random.random() < P:
              G_null.nodes[j]["trait"] = 1
          if G_null.nodes[j]["trait"] == 1 and G_null.nodes[i]['trait'] == 0:
            if random.random() < P:
              G_null.nodes[i]["trait"] = 1

  #Link updating
  for i in orderlist:
    for j in orderlist:
      if j > i:
        if (not G_null.has_edge(i,j)) and (random.random() < pc):
          #connect if random value between 0 and 1 is lower than the connection chance.
          #At 1 it is always lower, at 0 it never is.
          G_null.add_edge(i, j)
        if G_null.has_edge(i, j) and random.random() < pdis:
          G_null.remove_edge(i, j)

  return G_null

#This function is adapted (for degree) from Moser & Smaldino's code for "Innovation-Facilitating Networks Create Inequality", from their github https://github.com/cmoserj/Potions-Model/blob/v1.0.0/README.md.
def compute_gini(G,N):
    degrees = list(G.degree)
    x = sorted([i[1] for i in degrees])
    if N*sum(x) !=0:
        B = sum( xi * (N-i) for i,xi in enumerate(x) ) / (N*sum(x))
        return (1 + (1/N) - 2*B)
    else:
        return "NA"

def collect_stats(Q,i,G,N,t,crossover,freq_t,fixation_list,degree,clustering,connected_graphs,aspl,nr_components,largest_component,distribution,freq,count,potion):
  if potion:
    #check for crossover
    for agent in G.nodes():
      items = [item[0] for item in G.nodes[agent]["inventory"]]
    if 'B4' in items or 'A4' in items:
      crossover = t+1

  #retrieve trait attributes, and calculate frequency, which = proportion of agents with trait = 1:
  traits = nx.get_node_attributes(G,"trait")
  count = sum(1 for node, trait in traits.items() if trait ==1)
  #If the varying input parameter is N (meaning Q = 1, see below),
  #the population average is taken by dividing by the current iteration value of N
  #(i.e), the current value of i in the 'for i in N' for-loop in the run_simulation function, see below):
  if Q == 1:
    freq = count/i
  #Otherwise, N is constant:
  else:
    freq = count/N
  freq_t.update({t:freq})
  if freq == 1:
    t_fixation = t
    fixation_list.append(t_fixation)

  #Collect network properties
  #Connected components:
  components = list(nx.connected_components(G))
  #The statistic i want here is the size of (the number of nodes in) the largest component:
  largest_component += len(max(components,key=len))
  nr_components += len(components)

  #Degree:
  list_of_node_degrees = []
  for k in G.nodes:
    list_of_node_degrees.append(G.degree[k])
  #Again, if varying input parameter = N, take the current iteration value of N.
  if Q == 1:
    degree += sum(list_of_node_degrees)/i
  else:
    degree += sum(list_of_node_degrees)/N

  #Degree distribution inequality:
  gini = compute_gini(G,N)
  if gini != "NA":
    distribution += gini

  #Clustering:
  #clustering += nx.transitivity(G) is the other possibility; slight difference in how clustering is calculated.
  clustering += nx.average_clustering(G)

  if len(G.nodes) > 0:
  #this condition makes sure we're not calculating connectivity for the null graph at t=0, which will get you an error
    if nx.is_connected(G):
      connected_graphs += 1
      #This is a simple way of calculating ASPL, but requires there to be a single connected component:
      #aspl_G += nx.average_shortest_path_length(G)

  #Smoother way of calculating ASPL: calculate it for each component, then average.
  avg_lengths = []
  for component in components:
    subgraph = G.subgraph(component)
    avg_lengths.append(nx.average_shortest_path_length(subgraph))
  aspl = sum(avg_lengths) / len(avg_lengths)

  return crossover, freq_t, fixation_list, degree, clustering, connected_graphs, aspl, nr_components, largest_component, distribution

def initialize_graph(N,g,N_init,Q,i):
  coordinatespace = [(x,y) for x in range(g) for y in range(g)]

  G = nx.Graph()

  #Again, if varying parameter is N, create i agents rather than N.
  if Q == 1:
    #choose N unique positions as starting positions:
    initpos = random.sample(coordinatespace,i)
    for j in range(i):
      G.add_node(j, position = initpos[j])
      if j < N_init:
        G.nodes[j]["trait"]=1
      else:
        G.nodes[j]["trait"]=0

  #if varying parameter is not N, initialize a graph of size N.
  else:
    initpos = random.sample(coordinatespace,N)
    for n in range(N):
      G.add_node(n, position=initpos[n])
      if n < N_init:
        G.nodes[n]["trait"]=1
      else:
        G.nodes[n]["trait"]=0

  return G

def get_trait_data(i, fixation_list, freq_t, singlerun_fixation,singlerun_freq):
  #only get the first time at which fixation is reached, and only get it if fixation was reached:
  if len(fixation_list) > 0:
    singlerun_fixation.update({i:fixation_list[0]})
  else:
    singlerun_fixation.update({i:"fixation not reached"})
  singlerun_freq.update({i:freq_t})

  return singlerun_fixation, singlerun_freq

def run_simulation(R,r,N,g,T,P,N_init,Q,compl=False,weight=0,potion=False,pdiff=0):
  #Note version 02/05/2024: there are still some commented print commands in here in order to troubleshoot why varying N does not work as expected.

  #Initialize the output dictionaries: will have the form {round number:{"singlerun" dict}} (see below for "singlerun" dicts).
  multirun_freq = {}
  multirun_fixation = {}

  multirun_degree = {}
  multirun_clustering = {}
  multirun_connectedness = {}
  multirun_aspl = {}
  multirun_nr_components = {}
  multirun_largest_component = {}
  multirun_distribution = {}

  null_multirun_freq = {}
  null_multirun_fixation = {}

  null_multirun_degree = {}
  null_multirun_clustering = {}
  null_multirun_connectedness = {}
  null_multirun_aspl = {}
  null_multirun_nr_components = {}
  null_multirun_largest_component = {}
  null_multirun_distribution = {}

  multirun_crossover = {}
  null_multirun_crossover = {}

  #Q is a parameter that determines which input parameter is the varying parameter for the current simulation run.
  #It's an index value of the list of possible varying parameters [r,N,g].
  varying_parameter = [r,N,g][Q]

  for round_number in range(R):
    #Initialize the output dictionaries of a single simulation round: 100 timesteps at a constant input parameter value.
    # Will have the form {parameter value:time-average network measure} (except in the case of connectedness, which is not a time-average but a count out of the 100 timesteps.)
    singlerun_degree = {}
    singlerun_clustering = {}
    singlerun_connectedness = {}
    singlerun_aspl = {}
    singlerun_nr_components = {}
    singlerun_largest_component = {}
    singlerun_distribution = {}

    singlerun_freq = {}
    singlerun_fixation = {}

    null_singlerun_degree = {}
    null_singlerun_clustering = {}
    null_singlerun_connectedness = {}
    null_singlerun_aspl = {}
    null_singlerun_nr_components = {}
    null_singlerun_largest_component = {}
    null_singlerun_distribution = {}

    null_singlerun_freq = {}
    null_singlerun_fixation = {}

    singlerun_crossover = {}
    null_singlerun_crossover = {}

    for i in range(varying_parameter):
      #Skip the N=0 iteration, which just means empty graphs:
      if Q == 1 and i == 0:
        continue
      #Initialize the variables storing the output parameter values at single timesteps.
      degree = 0
      clustering = 0
      connected_graphs = 0
      aspl = 0
      nr_components = 0
      largest_component = 0
      distribution = 0

      freq = 0
      count = 0
      freq_t ={}

      t_fixation = 0
      fixation_list = []

      null_degree = 0
      null_clustering = 0
      null_connected_graphs = 0
      null_aspl = 0
      null_nr_components = 0
      null_largest_component = 0
      null_distribution = 0

      null_freq = 0
      null_count = 0
      null_freq_t ={}

      null_t_fixation = 0
      null_fixation_list = []

      #t=0: initialize G as graph of N nodes with position and trait attributes; N_init nodes starting with trait = 1.
      G = initialize_graph(N,g,N_init,Q,i)

      #Also initialize G_null: much simpler, does not have positions or coordinate space.
      G_null = nx.Graph()
      if Q ==1:
        for j in range(i):
          G_null.add_node(j)
          if j < N_init:
            G_null.nodes[j]["trait"]=1
          else:
            G_null.nodes[j]["trait"]=0
      else:
        for n in range(N):
          G_null.add_node(n)
          if n < N_init:
            G_null.nodes[n]["trait"]=1
          else:
            G_null.nodes[n]["trait"]=0

      if potion:
        for agent in range(N):
          G.nodes[agent]["inventory"] = copy.deepcopy(starting_inventory)
          G_null.nodes[agent]["inventory"] = copy.deepcopy(starting_inventory)

      for t in range(T):
        #Depending on the chosen Q-value, one of the model parameters is varied from 0 up to that value.
        #A null model is run alongside it, at matching settings.
        if Q == 0:
          G = connect_when_in_range(G, g, i, P,compl,weight,potion,pdiff)
          if i <= 10: #note this solution assumes i will always be integer values.
            pc = list(np.round(np.linspace(0,1,11),1))[i]
            G_null = connect_at_random(G_null,pc,P,compl,weight,potion,pdiff)
        elif Q == 1:
          #In the varying N runs, N varies based on the above initialization of G and G_null.
          G = connect_when_in_range(G, g, r, P,compl,weight,potion,pdiff)
          G_null = connect_at_random(G_null,r/g,P,compl,weight,potion,pdiff)
        elif Q == 2:
          G = connect_when_in_range(G, i, r, P,compl,weight,potion,pdiff)
          #no comparable null model here

          #Crossover is set to 0 at each timestep except the one in which it is reached.
        crossover = 0
        crossover_null = 0

        crossover, freq_t, fixation_list, degree, clustering, connected_graphs, aspl, nr_components, largest_component, distribution  = collect_stats(Q,i,G,N,t,crossover,freq_t,fixation_list,degree,clustering,connected_graphs,aspl,nr_components, largest_component,distribution,freq,count,potion)

        if Q != 2:
        #don't collect null stats if g is varying; no corresponding null model.
          crossover_null, null_freq_t, null_fixation_list, null_degree, null_clustering, null_connected_graphs, null_aspl, null_nr_components, null_largest_component, null_distribution = collect_stats(Q,i,G_null,N,t,crossover_null,null_freq_t,null_fixation_list,null_degree,null_clustering,null_connected_graphs,null_aspl,null_nr_components, null_largest_component,null_distribution,null_freq,null_count,potion)

      singlerun_fixation, singlerun_freq = get_trait_data(i, fixation_list, freq_t, singlerun_fixation,singlerun_freq)

      if Q != 2:
        if Q == 0:
          #When the varying parameter is range, the null model parameter is pc, which is always varied between 0 and 1.
          if i <= 10:
            pc = list(np.round(np.linspace(0,1,11),1))[i] #note this solution does assume that i is always an integer.
            null_singlerun_fixation, null_singlerun_freq = get_trait_data(pc, null_fixation_list, null_freq_t, null_singlerun_fixation, null_singlerun_freq)

        else:
          null_singlerun_fixation, null_singlerun_freq = get_trait_data(i, null_fixation_list, null_freq_t, null_singlerun_fixation, null_singlerun_freq)


      #In collect_stats, single-timestep values have been summed throughout a full round of 100 timesteps, and to get a time-average they are here divided by T.

      singlerun_degree.update({i:[degree/T]})
      singlerun_clustering.update({i: [clustering/T]})
      singlerun_connectedness.update({i:[connected_graphs]})
      singlerun_aspl.update({i:[aspl/T]})
      singlerun_nr_components.update({i:[nr_components/T]})
      singlerun_largest_component.update({i:[largest_component/T]})
      singlerun_distribution.update({i:[distribution/T]})
      #Potion task output: if crossover occured, the "crossover" variable was set to True and cross_time keeps the timestep at which it did.
      if crossover:
        singlerun_crossover.update({i:crossover})
      else:
        singlerun_crossover.update({i:"crossover not reached"})

      #print(f'degree, average: {singlerun_degree}')

      if Q != 2:
      #Again, don't collect null data when input parameter is g.
        if Q == 0:
          if i <= 10:
            #print(f'nulldegree, pc,total:{null_degree}')
            pc = list(np.round(np.linspace(0,1,11),1))[i]
            null_singlerun_degree.update({pc:[null_degree/T]})
            null_singlerun_clustering.update({pc: [null_clustering/T]})
            null_singlerun_connectedness.update({pc:[null_connected_graphs]})
            null_singlerun_aspl.update({pc:[null_aspl/T]})
            null_singlerun_nr_components.update({pc:[null_nr_components/T]})
            null_singlerun_largest_component.update({pc:[null_largest_component/T]})
            null_singlerun_distribution.update({pc:[null_distribution/T]})

            if crossover_null:
              null_singlerun_crossover.update({pc:crossover_null})
            else:
              null_singlerun_crossover.update({pc:"crossover not reached"})
        else:
          #print(f'nulldegree,N,total:{null_degree}')
          null_singlerun_degree.update({i:[null_degree/T]})
          null_singlerun_clustering.update({i: [null_clustering/T]})
          null_singlerun_connectedness.update({i:[null_connected_graphs]})
          null_singlerun_aspl.update({i:[null_aspl/T]})
          null_singlerun_nr_components.update({i:[null_nr_components/T]})
          null_singlerun_largest_component.update({i:[null_largest_component/T]})
          null_singlerun_distribution.update({i:[null_distribution/T]})

          if crossover_null:
            null_singlerun_crossover.update({i:crossover_null})
          else:
            null_singlerun_crossover.update({i:"crossover not reached"})

            #print(f'nulldegree, pc: {null_singlerun_degree}')

          #print(f'nulldegree, N,avg: {null_singlerun_degree}')

    multirun_degree.update({round_number:singlerun_degree})
    multirun_clustering.update({round_number:singlerun_clustering})
    multirun_connectedness.update({round_number:singlerun_connectedness})
    multirun_aspl.update({round_number:singlerun_aspl})
    multirun_nr_components.update({round_number:singlerun_nr_components})
    multirun_largest_component.update({round_number:singlerun_largest_component})
    multirun_distribution.update({round_number:singlerun_distribution})

    multirun_fixation.update({round_number:singlerun_fixation})
    multirun_freq.update({round_number:singlerun_freq})

    multirun_crossover.update({round_number:singlerun_crossover})

    if Q != 2:
      null_multirun_degree.update({round_number:null_singlerun_degree})
      null_multirun_clustering.update({round_number:null_singlerun_clustering})
      null_multirun_connectedness.update({round_number:null_singlerun_connectedness})
      null_multirun_aspl.update({round_number:null_singlerun_aspl})
      null_multirun_nr_components.update({round_number:null_singlerun_nr_components})
      null_multirun_largest_component.update({round_number:null_singlerun_largest_component})
      null_multirun_distribution.update({round_number:null_singlerun_distribution})

      null_multirun_fixation.update({round_number:null_singlerun_fixation})
      null_multirun_freq.update({round_number:null_singlerun_freq})
      null_multirun_crossover.update({round_number:null_singlerun_crossover})

  return(multirun_crossover, multirun_freq, multirun_fixation,multirun_degree,multirun_clustering,multirun_connectedness,multirun_aspl,multirun_nr_components,multirun_largest_component, multirun_distribution, null_multirun_crossover,
         null_multirun_freq, null_multirun_fixation, null_multirun_degree, null_multirun_clustering, null_multirun_connectedness,null_multirun_aspl,null_multirun_nr_components,null_multirun_largest_component, null_multirun_distribution)
  #Note: if g is varying, null dictionaries will simply return empty.

#Calling the function for varying range between 0 and 10, R=100, T=100, N=10, g=10, SI diffusion P=0.05:

datar = run_simulation(100,11,10,10,100,0.05)

#Calling the function for varying N between 0 and 100, r=2, potion task:

dataN = run_simulation(100,2,101,10,100,0,potion=True,pdiff=0.05)

#Calling the function for varying g between 0 and 50, N=10, r=5, complex contagion:

datag = run_simulation(100,5,10,51,0,compl=True,weight=0.1)
