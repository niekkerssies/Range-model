# -*- coding: utf-8 -*-
"""2. Plots

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1itwl25OKTVbSAYBycplLn1UdvyY6yvJp

# 3. Plotting results

This code assumes the "data" object created as output by the code in the file "model."

The summary_and_plot function takes the output dictionaries created by calling run_simulation, and creates visualizations and summaries of that output.

Subfunctions create the different kinds of plots and collect the summary statistics of the output dictionaries.

There's three types of plots that are created by this function. Type 1: plots where the x-axes represent the varying input parameter, and the y-axes represent network measure values. These are created by the "create_plot"  and "ceate_plot_null_range" functions. Type 2: plots that represent average diffusion over time per input parameter value. These visualize the SI, CE and complex contagion processes (see the "model" file). Type 3: bar plots that visualize the number of "crossover" occurances in the potion task (see "model" file), per input parameter value.

"Create_plot" is a subfunction used to generate the network properties (y-axis) vs. input parameter (x-axis) plots. First, a scatterplot is created in which points are results for single rounds (as explained above, these are time-averaged network properties over T timesteps, except for connectivity which is a simple count). If R=100, each input parameter value on the x axis will have 100 results. Second, a trend line is drawn connecting the averages across these R single-round measures. Third, a transparent area is created corresponding to 1.5 standard deviations around this average. The function takes as input:

-index number of the current subplot (a matplotlib object of 4 subplots axes[0] through axes [4] is created in summary_and_plot);

-the input argument of summary_and_plot() "parameter_label", which records the variable that was varied in the run_simulation call;

-"title", also copied from the input from the master function summary_and_plot();

-the relevant output dictionary of run_simulation;

-the dictionary storing the summary statistics of that output dictionary (created earlier in the summary_and_plot function, see below)

The final network structure graphs show both the range and the null results in a single graph. The "Create_plot_null_range" function is there specifically to plot runs where the varying parameter is range. Because the corresponding null-model parameter is not range (in integers) but _P(connect)_ (in decimals), these plots cannot strictly be plotted on the same x-axis. Instead, this function adds a 'second x-axis' against which the null results are plotted.

"Create_diffusion_plot" visualizes the diffusion processes. On the x-axis it puts time, on the y-axis, the frequencies of I (SI and complex contagion) or of A and B. Rather than plotting each single run, the average across rounds is taken of the frequency at each timestep. The result is an average diffusion over time curve for each input parameter value, from frequency is 0 to a maximum of 1. In the cultural evolution model, negative values represent higher frequency of trait B (-1 means every agent has adopted B), and positive values represent higher frequency of trait A (1 means every agent has adopted A).
This function also collects the summary statistics of the plotted values: mean, standard deviation, minimum and maximum of the across-round averages of trait frequencies.

"Create_potion_plot" creates bar plots that record the number of simulation rounds (out of a 100) in which a 'crossover event' (see "model" file) occured after 100 timesteps. On the x axis are the input parameter values.

The "summary_and_plot" function unpacks the results from run_simulation in another series of nested for-loops (simply to reformat the {R:{i{value}} dictionaries to {i{R:{value}} dictionaries), and creates plots of the network and diffusion process measures.

"summary_stats" calculates averages, standard deviations, minima and maxima given the output dictionaries created by the code in the "model" file.

Fixation times, which have a slightly different structures from the rest of the outputs, are summarized seperately by the "summarize_fixationtimes_diffusion" function.

The summary_and_plot() function takes as input variables:

-the results dictionaries from run_simulation;

-"title", a string describing the plotted results;

-"parameter_label", a string describing the input parameter variable that was used in the simulation run;

-"param_values": this is a list of all the values that were taken by the varying input parameter.

To plot the results, call the summary_and_plot function. The arguments are (results,title,parameter_label,param_values,print_summary=True). For results, simply put the 'data' object defined by the run_simulation call (the result of script 1). For title, you can create a description of the output plots; i usually put "Average network properties of communication and transmission graph under varying [varying parameter]." For parameter_label, put the name of the varying input parameter chosen in the simulation run: "Range","N","g",or "P". For param_values, create a list of which the entries correspond to the values taken by the varying parameter. For P, this is list(round(np.linspace(0,11,1),1)); for the other parameters, it's list(range([chosen maximum value])). Below are some example calls.
"""

import networkx as nx
import numpy as np
import random
import matplotlib.pyplot as plt
import math
import scipy
import pandas as pd
import copy

plt.rcParams.update({'figure.figsize': (10, 10)})
#this just globally sets the figure size

def create_plot(index, axes, parameter_label, title, multirundict, stats_per_value, null):
    axes[index].set_title(f"{parameter_label} vs. {title}")

    # Get averages and standard deviations
    averages = np.array([stats_per_value[value][0] for value in stats_per_value.keys()])
    standdevs = np.array([stats_per_value[value][1] for value in stats_per_value.keys()])

    # Filter out None values (relevant for small world index and gini index outcomes)
    filtered_averages = np.array([item for item in averages if item is not None])
    filtered_standdevs = np.array([item for item in standdevs if item is not None])

    # Set colors: red is null model, blue is range model.
    if null == False:
        linecolor = 'blue'
        areacolor = 'lightsteelblue'
        dotcolor = 'cornflowerblue'
    else:
        linecolor = 'red'
        areacolor = 'mistyrose'
        dotcolor = 'lightcoral'

    # Initialize a flag to check if there are valid y-values
    y_values_flag = False

    # Loop through rounds in multirundict
    for round_number in range(len(next(iter(multirundict.values())))):
        x_values = []
        y_values = []

        for x_value in stats_per_value.keys():
            y_value = multirundict.get(x_value, ["NA"] * (round_number + 1))[round_number]
            if y_value != "NA":
                x_values.append(x_value)
                y_values.append(y_value)

        if x_values and y_values:
            y_values_flag = True
            x_values = np.array(x_values)
            y_values = np.array(y_values)
            # Scatter plot for each round
            axes[index].scatter(x_values, y_values, color=dotcolor, alpha=0.3, s=2)

    if null:
      label= 'Null model'
    else:
      label = 'Range model'

    # Plot trend line through averages and fill standard deviation area
    if y_values_flag:
        valid_x_values = np.array([x for x, avg in zip(stats_per_value.keys(), averages) if avg is not None])
        axes[index].plot(valid_x_values, filtered_averages, color=linecolor, label=label)
        axes[index].fill_between(valid_x_values,
                                 filtered_averages - 1.5 * filtered_standdevs,
                                 filtered_averages + 1.5 * filtered_standdevs,
                                 color=areacolor,
                                 alpha=0.3)
        axes[index].set_xlabel(parameter_label)
        axes[index].set_ylabel(title)
        #axes[index].legend(loc='upper right', bbox_to_anchor=(1, 1))

    return axes[index]

def create_plot_null_range(index, axes, parameter_label, second_title, multirundict, stats_per_value):
    ax = axes[index].twiny()

    # Get averages and standard deviations
    averages = np.array([stats_per_value[value][0] for value in stats_per_value.keys()])
    standdevs = np.array([stats_per_value[value][1] for value in stats_per_value.keys()])

    # Filter out None values
    filtered_averages = np.array([item for item in averages if item is not None])
    filtered_standdevs = np.array([item for item in standdevs if item is not None])

    for round_number in range(len(next(iter(multirundict.values())))):  # Adjusted to get the length from the first key's value
        x_values = []
        y_values = []

        for x_value in stats_per_value.keys():
            y_value = multirundict.get(x_value, ["NA"] * (round_number + 1))[round_number]
            if y_value != "NA":
                x_values.append(x_value)
                y_values.append(y_value)

        if x_values and y_values:
            x_values = np.array(x_values)
            y_values = np.array(y_values)
            # Scatter plot for each round
            ax.scatter(x_values, y_values, color='lightcoral', alpha=0.3, s=2)

    # Plot averages and standard deviation fill area
    if len(filtered_averages) > 0:
        valid_x_values = np.array([x for x, avg in zip(stats_per_value.keys(), averages) if avg is not None])
        ax.plot(valid_x_values, filtered_averages, color='red', label='Null model')
        ax.fill_between(valid_x_values,
                        filtered_averages - 1.5 * filtered_standdevs,
                        filtered_averages + 1.5 * filtered_standdevs,
                        color='mistyrose',
                        alpha=0.3)
        ax.set_xlabel(parameter_label)
        #ax.legend(loc='upper right', bbox_to_anchor=(1, 0.9))

    return ax

def create_diffusion_plot(index,axes,parameter_label,input_param,freqdict):
  axes[index].set_title(f'{parameter_label} frequency over time')

  t_values = list(freqdict[1][1].keys())
  R_values = list(freqdict[1].keys())
  values = list(freqdict.keys())

  #This plot: on x, timesteps. On y, we have the average value across rounds of
  #the trait frequency at timestep x.

  sumstats = {}

  for value in values:
    R_averages_at_t = []
    for t in t_values:
      frequencies_at_t = []
      for round in R_values:
        frequencies_at_t.append(freqdict[value][round][t])
      R_averages_at_t.append(np.round(np.mean(frequencies_at_t),3))

    xlist = [t for t in t_values]
    ylist = R_averages_at_t
    axes[index].plot(xlist,ylist,label=f'{input_param}= {value}')
    axes[index].set_xlabel('Timestep')
    axes[index].set_ylabel('Trait frequency')
    axes[index].set_title('Diffusion over time')
    axes[index].legend()

    sumstats.update({value:[np.mean(R_averages_at_t),np.min(R_averages_at_t),np.max(R_averages_at_t)]})

  return axes[index], sumstats

def create_potion_plot(index,axes,parameter_label,input_param,crossoverdict,null):
  axes[index].set_title(f'{input_param} frequency over time')

  values = list(crossoverdict.keys())
  rounds = list(crossoverdict[1].keys())

  #Potion task bar plots: on x, the varying parameter, on y amount of crossover events
  #out of R rounds (given T timesteps).

  #entries of multirun_crossover have {value: {round: [list of timesteps at which crossover occured]}

  xlist = values
  ylist = []
  for value in values:
    count = 0
    for round in rounds:
      if crossoverdict[value][round] != 'crossover not reached':
        count += 1
    ylist.append(count)

  if null and parameter_label == "P(connect)":
    width = 0.08
    axes[index].bar(xlist,ylist,width=width)
    axes[index].set_ylabel(f'Crossovers reached out of 100 rounds')
    axes[index].set_xlabel(f'P(connect)')
    axes[index].set_xticks(values)
    max_y_null = max(ylist)
    axes[index].set_yticks(range(0, max_y_null + 1))
    #axes[1].set_xlim(0,1)

  else:
    axes[index].bar(xlist,ylist)
    axes[index].set_xticks(values)
    axes[index].set_ylabel(f'Crossovers reached out of 100 rounds')
    axes[index].set_xlabel(f'{parameter_label}')
    max_y = max(ylist)
    axes[index].set_yticks(range(0, max_y + 1))

def summary_stats(valuedict,inputvalue):
  avg,sd,minval,maxval = 0,0,0,0
  outputvalues = np.array(list((valuedict[inputvalue]).values()))
  #For those runs where all of the timesteps got you an undefined value of SW or Gini, outputvalue = "NA".
  filtered_output = np.array([item for item in outputvalues if not isinstance(item, str)])
  if len(filtered_output) == 0:
    avg,sd,min,maxval = None,None,None,None
  else:
    avg = np.mean(outputvalues)
    sd = np.std(outputvalues)
    minval = np.min(outputvalues)
    maxval = np.max(outputvalues)
  #print(avg,sd,minval,maxval)
  return(avg,sd,minval,maxval)

def summary_and_plot(results,title,parameter_label,CE=False,potion=False):
  multirun_crossover, multirun_freq, multirun_fixation,multirun_freqAB,multirun_fixationAB,multirun_degree,multirun_clustering,multirun_aspl,multirun_nr_components,multirun_largest_component, multirun_distribution, multirun_SWness,null_multirun_crossover,null_multirun_freq, null_multirun_fixation,null_multirun_freqAB,null_multirun_fixationAB, null_multirun_degree, null_multirun_clustering,null_multirun_aspl,null_multirun_nr_components,null_multirun_largest_component, null_multirun_distribution, null_multirun_SWness = results

  param_values = list(range(len(multirun_degree.keys())))

  #Summary stats dictionaries to be filled below by summary_stats() function. Format: {(output measure value:(avg,sd,min,max of R rounds of T timesteps))}
  deg_stats_per_value = {}
  cc_stats_per_value = {}
  aspl_stats_per_value = {}
  nrcomp_stats_per_value = {}
  lcomp_stats_per_value = {}
  distr_stats_per_value = {}
  SW_stats_per_value = {}
  fixtime_stats_per_value = {}
  fixtimeAB_stats_per_value = {}


  null_deg_stats_per_value = {}
  null_cc_stats_per_value = {}
  null_aspl_stats_per_value = {}
  null_nrcomp_stats_per_value = {}
  null_lcomp_stats_per_value = {}
  null_distr_stats_per_value = {}
  null_SW_stats_per_value = {}

  # For each parameter value, calculate statistics over the 100 runs done at that parameter value.
  for value in param_values:
    if parameter_label == 'N' and value == 0:
      continue
    deg_stats_per_value.update({value:summary_stats(multirun_degree,value)})
    cc_stats_per_value.update({value:summary_stats(multirun_clustering,value)})
    aspl_stats_per_value.update({value:summary_stats(multirun_aspl,value)})
    nrcomp_stats_per_value.update({value:summary_stats(multirun_nr_components,value)})
    lcomp_stats_per_value.update({value:summary_stats(multirun_largest_component,value)})
    distr_stats_per_value.update({value:summary_stats(multirun_distribution,value)})
    SW_stats_per_value.update({value:summary_stats(multirun_SWness,value)})

    nullvalue = value
    if parameter_label != 'g':
      if parameter_label == 'Range':
        if value <= 10:
          nullvalue = list(np.round(np.linspace(0, 1, 11), 1))[value]
      null_deg_stats_per_value.update({nullvalue: summary_stats(null_multirun_degree,nullvalue)})
      null_cc_stats_per_value.update({nullvalue: summary_stats(null_multirun_clustering,nullvalue)})
      null_aspl_stats_per_value.update({nullvalue: summary_stats(null_multirun_aspl,nullvalue)})
      null_nrcomp_stats_per_value.update({nullvalue: summary_stats(null_multirun_nr_components,nullvalue)})
      null_lcomp_stats_per_value.update({nullvalue: summary_stats(null_multirun_largest_component,nullvalue)})
      null_distr_stats_per_value.update({nullvalue: summary_stats(null_multirun_distribution,nullvalue)})
      null_SW_stats_per_value.update({nullvalue: summary_stats(null_multirun_SWness,nullvalue)})

  #Plots of input parameters(x) versus network structure outcomes (y):

  # Create 2 rows of four subplots
  fig, axes = plt.subplots(2, 4, figsize=(20, 12))
  axes = axes.flatten()

  axes[0] = create_plot(0, axes, parameter_label,'Average degree',multirun_degree, deg_stats_per_value,False)
  axes[1] = create_plot(1, axes, parameter_label, 'Clustering coefficient', multirun_clustering, cc_stats_per_value, False)
  axes[2] = create_plot(2, axes, parameter_label, 'Average shortest path length', multirun_aspl,aspl_stats_per_value , False)
  axes[3] = create_plot(3, axes, parameter_label, 'Number of components', multirun_nr_components, nrcomp_stats_per_value , False)
  axes[4] = create_plot(4, axes, parameter_label, 'Size of largest component', multirun_largest_component, lcomp_stats_per_value , False)
  axes[5] = create_plot(5, axes, parameter_label, 'Gini-coefficient of degree distribution',multirun_distribution, distr_stats_per_value , False)
  axes[6] = create_plot(6, axes, parameter_label, 'Small-world index', multirun_SWness,SW_stats_per_value , False)

  if parameter_label != 'g':

    if parameter_label == 'Range':
      null_label = 'P(connect)'

      ax0 = create_plot_null_range(0,axes,null_label,'P(connect)',null_multirun_degree,null_deg_stats_per_value)
      ax1 = create_plot_null_range(1,axes,null_label,'Clustering coefficient',null_multirun_clustering,null_cc_stats_per_value )
      ax2 = create_plot_null_range(2,axes,null_label,'Average shortest path length',null_multirun_aspl,null_aspl_stats_per_value )
      ax3 = create_plot_null_range(3,axes,null_label,'Number of components',null_multirun_nr_components,null_nrcomp_stats_per_value )
      ax4 = create_plot_null_range(4,axes,null_label,'Size of largest component',null_multirun_largest_component,null_lcomp_stats_per_value )
      ax5 = create_plot_null_range(5,axes,null_label,'Gini-coefficient of degree distribution',null_multirun_distribution, null_distr_stats_per_value )
      ax6 = create_plot_null_range(6,axes,null_label,'Small-world-ness',null_multirun_SWness,null_SW_stats_per_value )

    else:
      null_label = parameter_label

      axes[0] = create_plot(0,axes,null_label,'Average degree',null_multirun_degree,null_deg_stats_per_value,True)
      axes[1] = create_plot(1,axes,null_label,'Clustering coefficient',null_multirun_clustering, null_cc_stats_per_value,True)
      axes[2] = create_plot(2,axes,null_label,'Average shortest path length',null_multirun_aspl, null_aspl_stats_per_value,True)
      axes[3] = create_plot(3,axes,null_label,'Number of components',null_multirun_nr_components, null_nrcomp_stats_per_value,True)
      axes[4] = create_plot(4,axes,null_label,'Size of largest component',null_multirun_largest_component, null_lcomp_stats_per_value,True)
      axes[5] = create_plot(5,axes,null_label,'Gini-coefficient of degree distribution',null_multirun_distribution, null_distr_stats_per_value,True)
      axes[6] = create_plot(6,axes,null_label,'Small-world-ness',null_multirun_SWness,null_SW_stats_per_value,True)

    fig.delaxes(axes[7])
    plt.tight_layout()
    plt.show()

    if potion:

      fig,axes = plt.subplots(1,2,figsize = (20,5))

      axes[0] = create_potion_plot(0,axes,'Range','Crossover',data[0],False)

      axes[1] = create_potion_plot(1,axes,'P(connect)','Crossover',data[12],True)

      plt.tight_layout()
      plt.show()

    else:

      if CE:
        freqdict = multirun_freqAB
        null_freqdict = null_multirun_freqAB

      else:
        freqdict = multirun_freq
        null_freqdict = null_multirun_freq

      fig,axes = plt.subplots(1,2,figsize = (20,5))
      param_label = 'I-state'

      axes[0], sumstats = create_diffusion_plot(0,axes,param_label,'Range',freqdict)

      if parameter_label != 'g':
        axes[1], sumstats_null = create_diffusion_plot(1,axes,param_label,'P(connect)',null_freqdict)

      plt.show()

      #Summary statistics diffusion plot:
      print("Diffusion plot range model summary statistics:\n")
      print('Trait frequency:\n', pd.DataFrame(sumstats, index=['Average', 'Min', 'Max']).T, '\n')

      print("Diffusion plot null model summary statistics:\n")
      print('Trait frequency:\n', pd.DataFrame(sumstats_null, index=['Average', 'Min', 'Max']).T, '\n')

    #Summary statistics for more exact reference:

  print("Range model summary statistics:\n")
  print('Degree:\n', pd.DataFrame(deg_stats_per_value, index=['Average', 'SD', 'Min', 'Max']).T, '\n')
  print('Clustering coefficient:\n', pd.DataFrame(cc_stats_per_value, index=['Average', 'SD', 'Min', 'Max']).T, '\n')
  print('Average shortest path length:\n', pd.DataFrame(aspl_stats_per_value, index=['Average', 'SD', 'Min', 'Max']).T, '\n')
  print('Number of connected components:\n', pd.DataFrame(nrcomp_stats_per_value, index=['Average', 'SD', 'Min', 'Max']).T, '\n')
  print('Size of largest component:\n', pd.DataFrame(lcomp_stats_per_value, index=['Average', 'SD', 'Min', 'Max']).T, '\n')
  print('Gini-coefficient of degree distribution:\n', pd.DataFrame(distr_stats_per_value, index=['Average', 'SD', 'Min', 'Max']).T, '\n')
  print('Small-world index:\n', pd.DataFrame(SW_stats_per_value, index=['Average', 'SD', 'Min', 'Max']).T, '\n')

  print("Null model summary statistics:\n")
  print('Degree:\n', pd.DataFrame(null_deg_stats_per_value, index=['Average', 'SD', 'Min', 'Max']).T, '\n')
  print('Clustering coefficient:\n', pd.DataFrame(null_cc_stats_per_value, index=['Average', 'SD', 'Min', 'Max']).T, '\n')
  print('Average shortest path length:\n', pd.DataFrame(null_aspl_stats_per_value, index=['Average', 'SD', 'Min', 'Max']).T, '\n')
  print('Number of connected components:\n', pd.DataFrame(null_nrcomp_stats_per_value, index=['Average', 'SD', 'Min', 'Max']).T, '\n')
  print('Size of largest component:\n', pd.DataFrame(null_lcomp_stats_per_value, index=['Average', 'SD', 'Min', 'Max']).T, '\n')
  print('Gini-coefficient of degree distribution:\n', pd.DataFrame(null_distr_stats_per_value, index=['Average', 'SD', 'Min', 'Max']).T, '\n')
  print('Small-world index:\n', pd.DataFrame(null_SW_stats_per_value, index=['Average', 'SD', 'Min', 'Max']).T, '\n')

#Call corresponding to example 1 in script 1: varying parameter is range between 0 and 10, diffusion process is SI.
summary_and_plot(datar,"Average network properties and diffusion under varying communication range",'Range')

#Call corresponding to example 2: varying parameter is N between 0 and 100, diffusion process is potion task.
#summary_and_plot(dataN,"Average network properties and potion task performance under varying communication range","N",list(range(101)))

#Call corresponding to example 3: varying parameter is g between 0 and 50, diffusion process is complex contagion.
#summary_and_plot(datag,"Average network properties and diffusion under varying communication range","g",list(range(51)))
